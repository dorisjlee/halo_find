{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the jobs crashed because of [this issue](https://github.com/scikit-learn/scikit-learn/issues/3048) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified MiniBatchKMeans so that it doesn't compute label upfront but does it in the fit and predict procedure, this avoids the dot product matrix multiplication of the two large arrays (which is what caused the memory used to spike and crash). The initialization procedures has all been set to the default values . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 clusters test\n",
      "Loading Particle Data\n",
      "Creating train test split samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import yt\n",
    "import sklearn\n",
    "yt.funcs.mylog.setLevel(50)\n",
    "import sys\n",
    "k=100\n",
    "print \"{} clusters test\".format(k)\n",
    "print \"Loading Particle Data\"\n",
    "ds = yt.load(\"../ds14_scivis_0128_e4_dt04_1.0000\")\n",
    "ad = ds.all_data()\n",
    "x = ad[(\"all\",\"particle_position_x\")]\n",
    "y = ad[(\"all\",\"particle_position_y\")]\n",
    "z = ad[(\"all\",\"particle_position_z\")]\n",
    "print \"Creating train test split samples\"\n",
    "idx = ad[(\"all\",\"particle_index\")]\n",
    "N = 1000000\n",
    "train = np.array([idx[N:],x[N:],y[N:],z[N:]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MiniBatchKMeans(init='k-means++', n_clusters=k, batch_size=3*k,n_init=10, max_no_improvement=10, verbose=0, compute_labels=False)\n",
    "clf.fit(train[:,1:])\n",
    "labels = clf.predict(train[:,1:])\n",
    "centers=clf.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
